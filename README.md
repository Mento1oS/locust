# Отчет по нагрузочному тестированию REST и gRPC сервисов «Словарь терминов»

## 1. Описание тестируемого приложения

**Архитектура:**  
- REST: FastAPI, эндпоинты `/terms/` (CRUD)  
- gRPC: Python + protobuf, сервис `Glossary` с методами `ListTerms`, `CreateTerm`  
- Используется база данных: SQLite

**Используемые технологии:**  
- Python 3.12.2
- Locust 2.43.1

## 2. Настройки тестовой среды

**Аппаратные ресурсы:**  
- CPU: 14  
- RAM: 16 GB
- Сеть: wi-fi, 100 Mb/s

**Архитектура стенда:**  
- REST-сервис: `localhost:8000`  
- gRPC-сервис: `localhost:50051`  
- Locust клиент: `localhost:8089` и `localhost:8090`  

**Версия Locust:** 2.43.1  

## 3. Тестовые сценарии

### 3.1 Лёгкая нагрузка (Sanity Check)

**Логика поведения пользователя (task flow):**  
- list_terms — 75%  
- create_term — 25%  

**Конфигурация нагрузки:**  
- Пользователи: 1
- Spawn rate: 1/sec  
- Длительность: 2 минуты  

**Работает стабильно и без ошибок, grpc-сервис обрабатывает запросы быстрее rps примерно одинаковый, деградация** 
**не наблюдалась**


### 3.2 Рабочая нагрузка (Normal)

**Task flow:** как выше  

**Конфигурация нагрузки:**  
- Пользователи: 10
- Spawn rate: 5/sec  
- Длительность: 10 минут  

**Работает стабильно и без ошибок, grpc-сервис обрабатывает запросы быстрее, rps примерно одинаковый, деградация** 
**не наблюдалась**

### 3.3 Стресс-тест

**Task flow:** как выше  

**Конфигурация нагрузки:**  
- Пользователи: 100
- Spawn rate: 10/sec  
- Длительность: 5 минут  

**Работает стабильно и без ошибок, grpc-сервис обрабатывает запросы быстрее, rps примерно одинаковый, деградация** 
**не наблюдалась, RPS держался на уровне 80 на протяжении всего эксперимента, но время ответа уже увеличилось для rest**
**сервиса**

**При увеличении  количества пользователей до 1000 rest сервис также не справился, произошёл queue stack overflow**
**Увеличение количества пользователей до 3000 для grpc сервиса в течение минуты не привело к ошибкам со стороны**
**сервиса, однако сам locust клиент не справился с испусканием такой нагрузки. Таким образом, предел grpc на локальной**
**машине я не нащупал.**

### 3.4 Тест на стабильность (Soak test)

**Task flow:** как выше  

**Конфигурация нагрузки:**  
- Пользователи: 20  
- Spawn rate: 5/sec  
- Длительность: 30 минут  

**Работает стабильно и без ошибок, grpc-сервис обрабатывает запросы быстрее, rps примерно одинаковый, деградация** 
**не наблюдалась, rps держадлся в районе 16 все полчаса.** 

## 4. Результаты тестирования

### 4.1 Основные метрики

| Сценарий             | Тип сервиса | RPS  | Среднее время ответа (ms) | P95 (ms) | P99 (ms) | Кол-во ошибок |
|----------------------|------------|------|---------------------------|----------|----------|---------------|
| Лёгкая нагрузка      | REST       | 0.8  | 24.94                     | 8        | 22       | 0             |
| Лёгкая нагрузка      | gRPC       | 1    | 3.87                      | 13       | 37       | 0             |
| Рабочая нагрузка     | REST       | 7.7  | 7.82                      | 13       | 19       | 0             |
| Рабочая нагрузка     | gRPC       | 8.8  | 3.41                      | 7        | 10       | 0             |
| Стресс               | REST       | 79.4 | 19.62                     | 8        | 57       | 0             |
| Стресс               | gRPC       | 78.6 | 2.16                      | 2        | 5        | 0             |
| Стабильность         | REST       | 15   | 9.33                      | 14       | 21       | 0             |
| Стабильность         | gRPC       | 16   | 3.09                      | 7        | 9        | 0             |


## 6. Заключение

# Отчет по нагрузочному тестированию REST и gRPC приложений-словарей

## Основные выводы

- gRPC показал значительно лучшую масштабируемость по сравнению с REST: при нагрузке в 3000 пользователей сервер gRPC выдерживал поток запросов, тогда как REST-сервер падал уже при 1000 пользователей.  
- REST проще интегрировать и дебажить, но имеет больший overhead на HTTP-запросы и сериализацию JSON.  
- gRPC более эффективен при высоких нагрузках и большом числе мелких запросов, обеспечивая меньшую латентность и более высокий RPS.  

## Рекомендации по оптимизации

- Для REST-сервиса: использовать HTTP/2, оптимизировать сериализацию JSON, внедрить кэширование и балансировку нагрузки.  
- Для gRPC: следить за ресурсами клиента при экстремальной нагрузке (потому что именно клиент может стать узким местом).  
- Во всех случаях: мониторить CPU, память и сеть на стороне сервера и клиента.  

## Возможные улучшения эксперимента

- Запустить нагрузочные тесты на отдельной машине, чтобы клиентская машина не ограничивала результаты.  
- Использовать несколько экземпляров клиентов gRPC для более точного измерения максимальной нагрузки.  
- Добавить более длительные soak-тесты, чтобы проверить стабильность при непрерывной нагрузке.  
- Включить более сложные сценарии (например, комбинацию чтения и записи с разной частотой).  

## Ограничения проведённого тестирования

- Тестирование проводилось на одной машине, что ограничивало максимальное число клиентов.  
- Для REST-сервиса узким местом оказался сервер, для gRPC — клиент.  
- Использовалась локальная сеть, результаты могут отличаться в реальной распределённой среде.  
- Метрики латентности и RPS могли быть искажены из-за влияния OS и других фоновых процессов.


## 7. Исследовательская задача

# Сравнительный анализ реализаций микросервисной архитектуры: REST, gRPC, GraphQL

Данная подборка включает результаты актуальных исследований и бенчмарков (период 2025–2026 гг.), сфокусированных на производительности и потреблении ресурсов.

---

### 1. Исследование масштабируемости и задержек (ResearchGate, 2025)
**Тема:** *Impact of Protocol Selection on Performance and Scalability in Microservices*.

*   **Методология:** Нагрузочное тестирование (от 100 до 5000 RPS) в распределенной среде.
*   **Результаты (Бенчмарки):**
    *   **Latency:** gRPC показал задержку на 70% ниже, чем REST при передаче сложных структур данных.
    *   **Масштабируемость:** При увеличении нагрузки в 10 раз, время отклика GraphQL выросло на 45%, в то время как gRPC сохранил стабильность с ростом всего на 12%.
    *   **Трафик:** Использование Protobuf (gRPC) сократило объем передаваемого сетевого трафика на 40% по сравнению с JSON (REST).

### 2. Сравнение потребления ресурсов (Jurnal Sisfokom, 2025)
**Тема:** *Comparative Analysis of RESTful, GraphQL, and gRPC APIs for Resource-Constrained Environments*.

*   **Методология:** Замер утилизации CPU и RAM на идентичных контейнеризированных микросервисах.
*   **Результаты (Бенчмарки):**
    *   **CPU:** GraphQL потребляет в среднем **33.1%** ресурсов процессора из-за сложности выполнения резолверов. REST потребляет **7.2%**, а gRPC — **4.8%**.
    *   **RAM:** GraphQL эффективнее при работе с большими объектами (использование памяти на 15% ниже, чем у REST), так как позволяет избежать передачи избыточных данных (over-fetching).
    *   **Response Time:** REST — 1.4 мс, gRPC — 2.0 мс, GraphQL — 2.8 мс (при простых единичных запросах).

### 3. Исследование эффективности агрегации (ACM/ScitePress, 2025)
**Тема:** *Performance Evaluation of API Models in Microservice-based Data Aggregation*.

*   **Методология:** Сравнение сценариев получения данных из 5 зависимых микросервисов для формирования одной страницы фронтенда.
*   **Результаты (Бенчмарки):**
    *   **Сетевые вызовы (Round-trips):** GraphQL сокращает количество запросов "клиент-сервер" на **60%** (1 запрос против 3–5 у REST).
    *   **Throughput (Пропускная способность):** gRPC лидирует в межсервисном взаимодействии, обрабатывая на **120%** больше транзакций в секунду, чем REST, благодаря HTTP/2.

---

### Резюме результатов (2026 год)

| Технология | Сильные стороны | Слабые стороны | Рекомендуемое применение |
| :--- | :--- | :--- | :--- |
| **gRPC (RPC)** | Максимальная скорость, бинарная сериализация, низкая нагрузка на CPU. | Сложность отладки, слабая поддержка браузерами напрямую. | **Межсервисное взаимодействие** (внутренние микросервисы). |
| **REST** | Простота, кэширование, универсальная поддержка. | Избыточность данных (over-fetching), медленнее на больших нагрузках. | **Публичные API**, внешние интеграции. |
| **GraphQL** | Гибкость, получение всех данных за один запрос, отсутствие лишних полей. | Высокая нагрузка на CPU, сложность реализации защиты от тяжелых запросов. | **BFF (Backend for Frontend)**, мобильные приложения. |

**Вывод:** На 2026 год стандартом считается комбинация: **gRPC** внутри системы для скорости и **GraphQL/REST** на внешнем контуре для удобства клиентов.
